{
  "issues": [
    {
      "name": "Searchkit Core (Lexical + Semantic)",
      "tasks": [
        "[x] Postgres migrations for `search_documents`, `search_dirty`, embedding tables",
        "[x] Language-specific lexical docs (pg_trgm + heavy normalization)",
        "[x] Language-specific embeddings (halfvec + semantic search helpers)",
        "[x] Active model registry (`embedding_models`) synced from config"
      ]
    },
    {
      "name": "Add BM25/FTS Lexical Search",
      "tasks": [
        "[x] Extend `search_documents` to store both raw lexical text (for FTS) and heavy-normalized text (for trigram) without changing the host callback interface",
        "[x] Add per-language `tsvector` column(s) and GIN index(es) for FTS",
        "[x] Implement `search.FTSSearch(...)` (plainto_tsquery/websearch_to_tsquery + ts_rank_cd) returning hits with scores",
        "[x] Ensure FTS is language-aware via regconfig (e.g. english/spanish/etc.) and document how language maps to regconfig",
        "[x] Add tests for FTS ranking + basic correctness on a small fixture set",
        "[x] Implement Reciprocal Rank Fusion (RRF) helper for merging FTS ranks + vector ranks (replace weighted-sum for regular search blending)",
        "[x] Add public `searchkit.Typeahead(...)` API (trigram-only) and `searchkit.Search(...)` API (FTS+vector via RRF) as the recommended entrypoints",
        "[x] Document recommended usage: typeahead=trigram, search=FTS+vector via RRF (no raw score mixing)"
      ]
    },
    {
      "name": "Single Worker Loop",
      "tasks": [
        "[x] `worker.RunOnceSearchkit(...)` entrypoint",
        "[x] Process `search_dirty` (upsert docs, enqueue embeddings, delete artifacts on delete)",
        "[x] Cursor-based backfill (`search_documents_backfill_state`, `embedding_vectors_backfill_state`)",
        "[x] Drain `embedding_tasks` and write `embedding_vectors`",
        "[x] Dead-letter terminal failures into `embedding_dead_letters`"
      ]
    },
    {
      "name": "Docs + Naming",
      "tasks": [
        "[x] Update `README.md` to be a host-facing manual",
        "[x] Remove remaining \"embeddingkit\" naming in code/comments"
      ]
    },
    {
      "name": "CJK/Korean Lexical Search: Add PGroonga (Typeahead + FTS replacement)",
      "tasks": [
        "=== GOAL ===",
        "[ ] Improve lexical search quality for `ja`/`zh`/`ko` (PGroonga-backed tokenization/matching) and make typeahead usable in native script for `ja`/`zh`/`ko`.",
        "[ ] Keep existing Postgres FTS (`tsvector` + `ts_rank_cd`) for stemmer-backed languages (en/es/de/...).",
        "",
        "=== PG SETUP (POSTGRES) ===",
        "[x] Document required Postgres packages + how to install in Docker (PGroonga + dependencies).",
        "[x] Add a migration to enable extension: `CREATE EXTENSION IF NOT EXISTS pgroonga;` (host must run with sufficient privileges).",
        "[x] Add PGroonga indexes for CJK/Korean lexical fields:\n  - target table: `<schema>.search_documents`\n  - columns: `raw_document` (native script) and/or `document` (heavy-normalized)\n  - define whether to index all rows or only languages in ('ja','zh','ko') (partial index strategy).",
        "",
        "=== SEARCH APIS (SEARCHKIT) ===",
        "[x] Add `search.PGroongaSearch(...)` returning hits with scores (entity_type/entity_id/language/score).",
        "[x] Add `searchkit.Search(...)` routing:\n  - if language in {ja,zh,ko}: use PGroonga lexical search\n  - else: use existing FTS lexical search",
        "[x] Add `searchkit.Typeahead(...)` routing:\n  - if language in {ja,zh,ko}: use PGroonga-backed typeahead (native-script)\n  - else: keep existing trigram-heavy-normalized typeahead",
        "[x] Define a scoring contract for public APIs:\n  - `searchkit.Search(...)` lexical scores are normalized to a consistent range (target: [0..1]) across backends/languages\n  - `searchkit.Typeahead(...)` scores remain [0..1] and are comparable across languages/backends",
        "",
        "=== SCORING / BLENDING ===",
        "[x] Normalize PGroonga lexical scores to match the same public score range used by English FTS/trigram.\n  - Goal: host apps (doujins/hentai0/etc.) must NOT need any language-specific tuning or score-range branching.",
        "[x] Implement normalization inside searchkit (not in host apps):\n  - public hit `Score` is always normalized (target: [0..1])\n  - (optional) expose `RawScore` / debug fields only in dev/test builds for calibration",
        "[x] Ensure deterministic ordering/tie-breakers for lexical hits (score desc, entity_type asc, entity_id asc).",
        "",
        "=== TESTING ===",
        "[x] Add integration tests (docker-compose or testcontainers) covering:\n  - Japanese query matches Japanese document tokens\n  - Chinese query matches Chinese document tokens\n  - Korean query matches Korean document tokens\n  - Regression: en/es/de use FTS path unchanged\n  - Typeahead returns expected items for native-script queries",
        "",
        "=== DOCS ===",
        "[x] Update `README.md` with:\n  - when PGroonga is required\n  - how language routing works\n  - behavior when extension is not installed (fallback)\n  - recommended query strategies for CJK/Korean"
      ]
    }
  ]
}
